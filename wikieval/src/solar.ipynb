{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "224d350d-758b-4f50-adbf-9deea27ff838",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.tuna.tsinghua.edu.cn/simple\n",
      "Requirement already satisfied: transformers in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 1)) (4.46.1)\n",
      "Requirement already satisfied: datasets in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 2)) (2.19.1)\n",
      "Requirement already satisfied: accelerate in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 3)) (0.33.0)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers->-r requirements.txt (line 1)) (3.16.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /opt/conda/lib/python3.10/site-packages (from transformers->-r requirements.txt (line 1)) (0.26.2)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from transformers->-r requirements.txt (line 1)) (1.25.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers->-r requirements.txt (line 1)) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers->-r requirements.txt (line 1)) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers->-r requirements.txt (line 1)) (2023.10.3)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers->-r requirements.txt (line 1)) (2.31.0)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /opt/conda/lib/python3.10/site-packages (from transformers->-r requirements.txt (line 1)) (0.4.1)\n",
      "Requirement already satisfied: tokenizers<0.21,>=0.20 in /opt/conda/lib/python3.10/site-packages (from transformers->-r requirements.txt (line 1)) (0.20.2)\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers->-r requirements.txt (line 1)) (4.66.1)\n",
      "Requirement already satisfied: pyarrow>=12.0.0 in /opt/conda/lib/python3.10/site-packages (from datasets->-r requirements.txt (line 2)) (14.0.1)\n",
      "Requirement already satisfied: pyarrow-hotfix in /opt/conda/lib/python3.10/site-packages (from datasets->-r requirements.txt (line 2)) (0.6)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from datasets->-r requirements.txt (line 2)) (0.3.8)\n",
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from datasets->-r requirements.txt (line 2)) (2.1.3)\n",
      "Requirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from datasets->-r requirements.txt (line 2)) (3.5.0)\n",
      "Requirement already satisfied: multiprocess in /opt/conda/lib/python3.10/site-packages (from datasets->-r requirements.txt (line 2)) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2024.3.1,>=2023.1.0 in /opt/conda/lib/python3.10/site-packages (from fsspec[http]<=2024.3.1,>=2023.1.0->datasets->-r requirements.txt (line 2)) (2024.3.1)\n",
      "Requirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from datasets->-r requirements.txt (line 2)) (3.10.10)\n",
      "Requirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from accelerate->-r requirements.txt (line 3)) (5.9.6)\n",
      "Requirement already satisfied: torch>=1.10.0 in /opt/conda/lib/python3.10/site-packages (from accelerate->-r requirements.txt (line 3)) (2.1.2+cu121)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets->-r requirements.txt (line 2)) (2.4.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets->-r requirements.txt (line 2)) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets->-r requirements.txt (line 2)) (24.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets->-r requirements.txt (line 2)) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets->-r requirements.txt (line 2)) (6.1.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.12.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets->-r requirements.txt (line 2)) (1.17.1)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets->-r requirements.txt (line 2)) (4.0.3)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.23.2->transformers->-r requirements.txt (line 1)) (4.8.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers->-r requirements.txt (line 1)) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers->-r requirements.txt (line 1)) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers->-r requirements.txt (line 1)) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers->-r requirements.txt (line 1)) (2024.2.2)\n",
      "Requirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate->-r requirements.txt (line 3)) (1.12)\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate->-r requirements.txt (line 3)) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate->-r requirements.txt (line 3)) (3.1.4)\n",
      "Requirement already satisfied: triton==2.1.0 in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate->-r requirements.txt (line 3)) (2.1.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets->-r requirements.txt (line 2)) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets->-r requirements.txt (line 2)) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets->-r requirements.txt (line 2)) (2023.3)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->datasets->-r requirements.txt (line 2)) (1.16.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /opt/conda/lib/python3.10/site-packages (from yarl<2.0,>=1.12.0->aiohttp->datasets->-r requirements.txt (line 2)) (0.2.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.10.0->accelerate->-r requirements.txt (line 3)) (2.1.5)\n",
      "Requirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.10.0->accelerate->-r requirements.txt (line 3)) (1.3.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "! pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dca16063-cca3-4b21-aeeb-d2502114c9d4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformers import (AutoModelForCausalLM, AutoTokenizer)\n",
    "from datasets import load_dataset, Dataset\n",
    "from typing import List, Dict, Optional\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "09a50fa1-4b7d-46ad-9282-0f3211fd19d1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c46c5c233d243e0980ca8f273927b0e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "RuntimeError",
     "evalue": "The NVIDIA driver on your system is too old (found version 11040). Please update your GPU driver by downloading and installing a new version from the URL: http://www.nvidia.com/Download/index.aspx Alternatively, go to: https://pytorch.org to install a PyTorch version that has been compiled with your version of the CUDA driver.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m device \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m----> 2\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mAutoModelForCausalLM\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m../models/SOLAR-10-7B-v1-0\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m                                             \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m                                             \u001b[49m\u001b[38;5;66;43;03m# torch_dtype=torch.float16, \u001b[39;49;00m\n\u001b[1;32m      5\u001b[0m \u001b[43m                                             \u001b[49m\u001b[43mdevice_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m tokenizer \u001b[38;5;241m=\u001b[39m AutoTokenizer\u001b[38;5;241m.\u001b[39mfrom_pretrained(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m../models/SOLAR-10-7B-v1-0\u001b[39m\u001b[38;5;124m\"\u001b[39m, \n\u001b[1;32m      7\u001b[0m                                           local_files_only\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/models/auto/auto_factory.py:564\u001b[0m, in \u001b[0;36m_BaseAutoModelClass.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m    562\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(config) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_model_mapping\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[1;32m    563\u001b[0m     model_class \u001b[38;5;241m=\u001b[39m _get_model_class(config, \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_model_mapping)\n\u001b[0;32m--> 564\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmodel_class\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    565\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mhub_kwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    566\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    567\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    568\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnrecognized configuration class \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconfig\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m for this kind of AutoModel: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    569\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModel type should be one of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(c\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mfor\u001b[39;00m\u001b[38;5;250m \u001b[39mc\u001b[38;5;250m \u001b[39m\u001b[38;5;129;01min\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_model_mapping\u001b[38;5;241m.\u001b[39mkeys())\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    570\u001b[0m )\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/modeling_utils.py:4225\u001b[0m, in \u001b[0;36mPreTrainedModel.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, config, cache_dir, ignore_mismatched_sizes, force_download, local_files_only, token, revision, use_safetensors, weights_only, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m   4215\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m dtype_orig \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   4216\u001b[0m         torch\u001b[38;5;241m.\u001b[39mset_default_dtype(dtype_orig)\n\u001b[1;32m   4218\u001b[0m     (\n\u001b[1;32m   4219\u001b[0m         model,\n\u001b[1;32m   4220\u001b[0m         missing_keys,\n\u001b[1;32m   4221\u001b[0m         unexpected_keys,\n\u001b[1;32m   4222\u001b[0m         mismatched_keys,\n\u001b[1;32m   4223\u001b[0m         offload_index,\n\u001b[1;32m   4224\u001b[0m         error_msgs,\n\u001b[0;32m-> 4225\u001b[0m     ) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_load_pretrained_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   4226\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4227\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstate_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4228\u001b[0m \u001b[43m        \u001b[49m\u001b[43mloaded_state_dict_keys\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# XXX: rename?\u001b[39;49;00m\n\u001b[1;32m   4229\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresolved_archive_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4230\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4231\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_mismatched_sizes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_mismatched_sizes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4232\u001b[0m \u001b[43m        \u001b[49m\u001b[43msharded_metadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msharded_metadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4233\u001b[0m \u001b[43m        \u001b[49m\u001b[43m_fast_init\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_fast_init\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4234\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlow_cpu_mem_usage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlow_cpu_mem_usage\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4235\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdevice_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice_map\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4236\u001b[0m \u001b[43m        \u001b[49m\u001b[43moffload_folder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moffload_folder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4237\u001b[0m \u001b[43m        \u001b[49m\u001b[43moffload_state_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moffload_state_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4238\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtorch_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4239\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhf_quantizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhf_quantizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4240\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkeep_in_fp32_modules\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkeep_in_fp32_modules\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4241\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgguf_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgguf_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4242\u001b[0m \u001b[43m        \u001b[49m\u001b[43mweights_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mweights_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4243\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4245\u001b[0m \u001b[38;5;66;03m# make sure token embedding weights are still tied if needed\u001b[39;00m\n\u001b[1;32m   4246\u001b[0m model\u001b[38;5;241m.\u001b[39mtie_weights()\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/modeling_utils.py:4728\u001b[0m, in \u001b[0;36mPreTrainedModel._load_pretrained_model\u001b[0;34m(cls, model, state_dict, loaded_keys, resolved_archive_file, pretrained_model_name_or_path, ignore_mismatched_sizes, sharded_metadata, _fast_init, low_cpu_mem_usage, device_map, offload_folder, offload_state_dict, dtype, hf_quantizer, keep_in_fp32_modules, gguf_path, weights_only)\u001b[0m\n\u001b[1;32m   4724\u001b[0m                 set_module_tensor_to_device(\n\u001b[1;32m   4725\u001b[0m                     model_to_load, key, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m\"\u001b[39m, torch\u001b[38;5;241m.\u001b[39mempty(\u001b[38;5;241m*\u001b[39mparam\u001b[38;5;241m.\u001b[39msize(), dtype\u001b[38;5;241m=\u001b[39mdtype)\n\u001b[1;32m   4726\u001b[0m                 )\n\u001b[1;32m   4727\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 4728\u001b[0m         new_error_msgs, offload_index, state_dict_index \u001b[38;5;241m=\u001b[39m \u001b[43m_load_state_dict_into_meta_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   4729\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmodel_to_load\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4730\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstate_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4731\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstart_prefix\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4732\u001b[0m \u001b[43m            \u001b[49m\u001b[43mexpected_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4733\u001b[0m \u001b[43m            \u001b[49m\u001b[43mdevice_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice_map\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4734\u001b[0m \u001b[43m            \u001b[49m\u001b[43moffload_folder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moffload_folder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4735\u001b[0m \u001b[43m            \u001b[49m\u001b[43moffload_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moffload_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4736\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstate_dict_folder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstate_dict_folder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4737\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstate_dict_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstate_dict_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4738\u001b[0m \u001b[43m            \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4739\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhf_quantizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhf_quantizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4740\u001b[0m \u001b[43m            \u001b[49m\u001b[43mis_safetensors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_safetensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4741\u001b[0m \u001b[43m            \u001b[49m\u001b[43mkeep_in_fp32_modules\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkeep_in_fp32_modules\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4742\u001b[0m \u001b[43m            \u001b[49m\u001b[43munexpected_keys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43munexpected_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4743\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4744\u001b[0m         error_msgs \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m new_error_msgs\n\u001b[1;32m   4745\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   4746\u001b[0m     \u001b[38;5;66;03m# Sharded checkpoint or whole but low_cpu_mem_usage==True\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/modeling_utils.py:993\u001b[0m, in \u001b[0;36m_load_state_dict_into_meta_model\u001b[0;34m(model, state_dict, start_prefix, expected_keys, device_map, offload_folder, offload_index, state_dict_folder, state_dict_index, dtype, hf_quantizer, is_safetensors, keep_in_fp32_modules, unexpected_keys, pretrained_model_name_or_path)\u001b[0m\n\u001b[1;32m    990\u001b[0m         param_device \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_local_dist_rank_0() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmeta\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    992\u001b[0m     \u001b[38;5;66;03m# For backward compatibility with older versions of `accelerate` and for non-quantized params\u001b[39;00m\n\u001b[0;32m--> 993\u001b[0m     \u001b[43mset_module_tensor_to_device\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparam_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparam_device\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mset_module_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    994\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    995\u001b[0m     hf_quantizer\u001b[38;5;241m.\u001b[39mcreate_quantized_param(model, param, param_name, param_device, state_dict, unexpected_keys)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/accelerate/utils/modeling.py:416\u001b[0m, in \u001b[0;36mset_module_tensor_to_device\u001b[0;34m(module, tensor_name, device, value, dtype, fp16_statistics, tied_params_map)\u001b[0m\n\u001b[1;32m    414\u001b[0m             module\u001b[38;5;241m.\u001b[39m_parameters[tensor_name] \u001b[38;5;241m=\u001b[39m param_cls(new_value, requires_grad\u001b[38;5;241m=\u001b[39mold_value\u001b[38;5;241m.\u001b[39mrequires_grad)\n\u001b[1;32m    415\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(value, torch\u001b[38;5;241m.\u001b[39mTensor):\n\u001b[0;32m--> 416\u001b[0m     new_value \u001b[38;5;241m=\u001b[39m \u001b[43mvalue\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    417\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    418\u001b[0m     new_value \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(value, device\u001b[38;5;241m=\u001b[39mdevice)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/cuda/__init__.py:298\u001b[0m, in \u001b[0;36m_lazy_init\u001b[0;34m()\u001b[0m\n\u001b[1;32m    296\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCUDA_MODULE_LOADING\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m os\u001b[38;5;241m.\u001b[39menviron:\n\u001b[1;32m    297\u001b[0m     os\u001b[38;5;241m.\u001b[39menviron[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCUDA_MODULE_LOADING\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLAZY\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 298\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_C\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cuda_init\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    299\u001b[0m \u001b[38;5;66;03m# Some of the queued calls may reentrantly call _lazy_init();\u001b[39;00m\n\u001b[1;32m    300\u001b[0m \u001b[38;5;66;03m# we need to just return without initializing in that case.\u001b[39;00m\n\u001b[1;32m    301\u001b[0m \u001b[38;5;66;03m# However, we must not let any *other* threads in!\u001b[39;00m\n\u001b[1;32m    302\u001b[0m _tls\u001b[38;5;241m.\u001b[39mis_initializing \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: The NVIDIA driver on your system is too old (found version 11040). Please update your GPU driver by downloading and installing a new version from the URL: http://www.nvidia.com/Download/index.aspx Alternatively, go to: https://pytorch.org to install a PyTorch version that has been compiled with your version of the CUDA driver."
     ]
    }
   ],
   "source": [
    "device = \"cuda\"\n",
    "model = AutoModelForCausalLM.from_pretrained(\"../models/SOLAR-10-7B-v1-0\", \n",
    "                                             local_files_only=True, \n",
    "                                             # torch_dtype=torch.float16, \n",
    "                                             device_map=device)\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"../models/SOLAR-10-7B-v1-0\", \n",
    "                                          local_files_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "cdaf4d58-7ea4-4f39-858b-74215d9e7edf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "MAX_EXAMPLES = 500\n",
    "MAX_FEWSHOTS = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "b5024d03-45ba-4b66-9524-c01399146ece",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd    \n",
    "jsonObj = pd.read_json(path_or_buf=\"../datasets/ASQA/dev.jsonl\", lines=True)\n",
    "dataset = Dataset.from_pandas(jsonObj)\n",
    "dataset = dataset.select(range(MAX_EXAMPLES))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "036f4722-b29c-4a81-8550-d92251d32278",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from prompts import (FEW_SHOT_EXAMPLES, PROMPT)\n",
    "\n",
    "few_shot_examples = '\\n\\n'.join(FEW_SHOT_EXAMPLES[:MAX_FEWSHOTS])\n",
    "prompts = [\n",
    "    PROMPT.format(few_shot_examples = few_shot_examples,\n",
    "                  question = data)\n",
    "    for data in dataset['ambiguous_question']\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "def9160f-5dbc-4253-badf-e22c1b655061",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10731524096"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.num_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f18a3c0a-c286-408c-a63e-c80d3a685455",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \"Explain the significance and applications of the formula a²+b²=c² in number theory.\"\n",
    "inputs = tokenizer(text, return_tensors=\"pt\").to(device)\n",
    "\n",
    "outputs = model.generate(**inputs, \n",
    "                         max_new_tokens=64, \n",
    "                         do_sample=False, )\n",
    "tokenizer.decode(outputs[0, inputs.input_ids.shape[1]:], pad_token_id = tokenizer.eos_token_id, skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "4b896cd6-2c2e-44b1-bbe5-074ac54f5f4c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "inputs = tokenizer(dataset['ambiguous_question'][0], return_tensors=\"pt\").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "e1611c16-8131-45cd-a7ea-a5e1b48c61cb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Who has the highest goals in world football?'"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['ambiguous_question'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "f8671f1b-931a-46bb-a3dc-8e453f6a3559",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "outputs = model.generate(**inputs, \n",
    "                         max_length=64, \n",
    "                         pad_token_id = tokenizer.eos_token_id, \n",
    "                         return_dict_in_generate=True, \n",
    "                         output_scores=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "33612ad5-e773-4397-b3fa-7da3fa2c1a13",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<s> Who has the highest goals in world football?\\nWho has the most goals in football in football in football in football in football in football in football in football in football in football in football in football in football in football in football in football in football in football in football in football in football in football in football in football'"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(outputs.sequences[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "29d0ed66-ddab-44f8-8ad7-3caaf0da06aa",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GenerateDecoderOnlyOutput(sequences=tensor([[    1,  6526,   659,   272,  7881,  7661,   297,  1526,  6569, 28804,\n",
       "            13, 11447,   659,   272,  1080,  7661,   297,  6569,   297,  6569,\n",
       "           297,  6569,   297,  6569,   297,  6569,   297,  6569,   297,  6569,\n",
       "           297,  6569,   297,  6569,   297,  6569,   297,  6569,   297,  6569,\n",
       "           297,  6569,   297,  6569,   297,  6569,   297,  6569,   297,  6569,\n",
       "           297,  6569,   297,  6569,   297,  6569,   297,  6569,   297,  6569,\n",
       "           297,  6569,   297,  6569]], device='cuda:0'), scores=(tensor([[-12.4966,  -9.4589,   4.2763,  ...,  -7.0494,  -8.2579,  -7.0620]],\n",
       "       device='cuda:0'), tensor([[-2.7341, -1.5249,  9.7068,  ..., -1.0406, -1.2222, -0.8011]],\n",
       "       device='cuda:0'), tensor([[-7.4548,  0.6265,  7.3069,  ..., -9.7692, -8.8949, -6.2715]],\n",
       "       device='cuda:0'), tensor([[-8.6624,  0.4954,  7.5608,  ..., -8.4176, -9.5677, -7.5875]],\n",
       "       device='cuda:0'), tensor([[-7.3200,  0.8186,  7.7449,  ..., -8.4163, -8.1161, -8.1980]],\n",
       "       device='cuda:0'), tensor([[-8.0566, -0.5274,  6.6712,  ..., -8.5696, -8.6834, -7.0340]],\n",
       "       device='cuda:0'), tensor([[ -9.3749,   1.2097,   7.5665,  ..., -10.8964,  -9.5095,  -9.4226]],\n",
       "       device='cuda:0'), tensor([[-8.2870,  1.0325,  7.9503,  ..., -9.3004, -9.1900, -8.0701]],\n",
       "       device='cuda:0'), tensor([[-7.7113,  2.4921,  9.0716,  ..., -9.1152, -8.4469, -8.5495]],\n",
       "       device='cuda:0'), tensor([[-7.9767,  2.0537,  7.8871,  ..., -8.4215, -8.8932, -7.9008]],\n",
       "       device='cuda:0'), tensor([[-7.5306,  2.5232,  9.8231,  ..., -8.2361, -7.8071, -6.8590]],\n",
       "       device='cuda:0'), tensor([[-5.8659,  3.0648,  9.5825,  ..., -8.4809, -8.3207, -7.2989]],\n",
       "       device='cuda:0'), tensor([[-8.3118,  2.8440,  9.6979,  ..., -8.6443, -8.9062, -7.0320]],\n",
       "       device='cuda:0'), tensor([[-6.6259,  2.8501,  8.8164,  ..., -8.9455, -8.7101, -7.4419]],\n",
       "       device='cuda:0'), tensor([[-8.6778,  2.2145,  8.4940,  ..., -8.7886, -9.2142, -6.8802]],\n",
       "       device='cuda:0'), tensor([[-6.8807,  2.7275,  8.6182,  ..., -8.8406, -8.7446, -7.5202]],\n",
       "       device='cuda:0'), tensor([[-8.7903,  2.2048,  8.0474,  ..., -8.6239, -9.3016, -7.0398]],\n",
       "       device='cuda:0'), tensor([[-6.9846,  2.7711,  8.5110,  ..., -8.8035, -8.9068, -7.7416]],\n",
       "       device='cuda:0'), tensor([[-8.6874,  2.4994,  8.3409,  ..., -8.3581, -9.3903, -7.1709]],\n",
       "       device='cuda:0'), tensor([[-6.8437,  3.0586,  8.6183,  ..., -8.7547, -8.8381, -7.7721]],\n",
       "       device='cuda:0'), tensor([[-8.5080,  2.7375,  8.5141,  ..., -8.0829, -9.2884, -7.0599]],\n",
       "       device='cuda:0'), tensor([[-6.7933,  3.2623,  8.6667,  ..., -8.8289, -8.8398, -7.6971]],\n",
       "       device='cuda:0'), tensor([[-8.3958,  2.9102,  8.6881,  ..., -8.1073, -9.1974, -6.9708]],\n",
       "       device='cuda:0'), tensor([[-6.7498,  3.4495,  8.7542,  ..., -8.9443, -8.9221, -7.7070]],\n",
       "       device='cuda:0'), tensor([[-8.1396,  2.9677,  8.8018,  ..., -8.0691, -9.1646, -6.8777]],\n",
       "       device='cuda:0'), tensor([[-6.5915,  3.6804,  8.9197,  ..., -8.9374, -8.9687, -7.7059]],\n",
       "       device='cuda:0'), tensor([[-8.0170,  3.1051,  8.8707,  ..., -7.9956, -9.2689, -6.7442]],\n",
       "       device='cuda:0'), tensor([[-6.4863,  3.8414,  9.0453,  ..., -8.9281, -9.0056, -7.7043]],\n",
       "       device='cuda:0'), tensor([[-7.9659,  3.2979,  8.9672,  ..., -7.9825, -9.4003, -6.6795]],\n",
       "       device='cuda:0'), tensor([[-6.5089,  3.9021,  9.0465,  ..., -9.0162, -8.9827, -7.7691]],\n",
       "       device='cuda:0'), tensor([[-7.9133,  3.2944,  8.9225,  ..., -8.0743, -9.3712, -6.7397]],\n",
       "       device='cuda:0'), tensor([[-6.6314,  3.9211,  9.0827,  ..., -9.0301, -8.9407, -7.8505]],\n",
       "       device='cuda:0'), tensor([[-8.0115,  3.2641,  8.8518,  ..., -8.1310, -9.1934, -6.9120]],\n",
       "       device='cuda:0'), tensor([[-6.8335,  3.8945,  8.9574,  ..., -9.0325, -8.8280, -7.8860]],\n",
       "       device='cuda:0'), tensor([[-8.2915,  3.1889,  8.7735,  ..., -8.1423, -9.0375, -6.9757]],\n",
       "       device='cuda:0'), tensor([[-7.1406,  3.7313,  8.7012,  ..., -8.9809, -8.7236, -7.8608]],\n",
       "       device='cuda:0'), tensor([[-8.5938,  3.0060,  8.5687,  ..., -7.9852, -8.9576, -6.8675]],\n",
       "       device='cuda:0'), tensor([[-7.3860,  3.6955,  8.5157,  ..., -8.9495, -8.6939, -7.8591]],\n",
       "       device='cuda:0'), tensor([[-8.7258,  2.9720,  8.5146,  ..., -7.9658, -8.9816, -6.7442]],\n",
       "       device='cuda:0'), tensor([[-7.4121,  3.9308,  8.6332,  ..., -9.1209, -8.7531, -7.8754]],\n",
       "       device='cuda:0'), tensor([[-8.6814,  3.1669,  8.6723,  ..., -8.0387, -8.8750, -6.6469]],\n",
       "       device='cuda:0'), tensor([[-7.2416,  4.1055,  8.8260,  ..., -9.1568, -8.7511, -7.8556]],\n",
       "       device='cuda:0'), tensor([[-8.3571,  3.4873,  8.9804,  ..., -8.1376, -8.7634, -6.5748]],\n",
       "       device='cuda:0'), tensor([[-6.8372,  4.3003,  9.0907,  ..., -9.1356, -8.7366, -7.8367]],\n",
       "       device='cuda:0'), tensor([[-7.7616,  3.8108,  9.3205,  ..., -8.1457, -8.7799, -6.4575]],\n",
       "       device='cuda:0'), tensor([[-5.9014,  4.9605, 10.1022,  ..., -9.1577, -8.5591, -7.8625]],\n",
       "       device='cuda:0'), tensor([[-6.8866,  4.3176, 10.0329,  ..., -8.0781, -8.6256, -6.3242]],\n",
       "       device='cuda:0'), tensor([[-6.1493,  4.8092, 10.0587,  ..., -9.2306, -8.5995, -7.9100]],\n",
       "       device='cuda:0'), tensor([[-7.0824,  4.1877, 10.0231,  ..., -8.1829, -8.5905, -6.4288]],\n",
       "       device='cuda:0'), tensor([[-6.1368,  4.6670,  9.9398,  ..., -9.1717, -8.6035, -7.8942]],\n",
       "       device='cuda:0'), tensor([[-7.1840,  4.0346,  9.8811,  ..., -8.0946, -8.5019, -6.5489]],\n",
       "       device='cuda:0'), tensor([[-5.9843,  4.5658,  9.9026,  ..., -9.0204, -8.5102, -7.8383]],\n",
       "       device='cuda:0'), tensor([[-6.9915,  3.9300,  9.8635,  ..., -7.9242, -8.3496, -6.5863]],\n",
       "       device='cuda:0'), tensor([[-6.2215,  4.3381,  9.4109,  ..., -9.0196, -8.5565, -7.8505]],\n",
       "       device='cuda:0')), logits=None, attentions=None, hidden_states=None, past_key_values=None)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "6033f489-5be9-413c-aa2f-146708dec031",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 10])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs.input_ids.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "679637b9-171b-40a5-9508-29a6f8f2df30",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([14.4823,  9.3588,  9.3508,  9.3450,  9.0621], device='cuda:0') tensor([  13,  764,  342, 6526,  415], device='cuda:0') ['\\n – | Who The']\n",
      "tensor([15.4404, 14.2568, 14.1118, 13.9307, 13.6776], device='cuda:0') tensor([11447,  3195,  6479, 26703,  1014], device='cuda:0') ['WhoWhatfootWhichThe']\n",
      "tensor([14.3441, 13.4724, 12.6928, 12.3255, 11.4236], device='cuda:0') tensor([  659,   349,    13, 13969,   460], device='cuda:0') ['has is\\n scored are']\n",
      "tensor([13.4148, 12.7340, 12.6190, 11.9187, 11.7300], device='cuda:0') tensor([  272, 13969,    13,  6526,  1080], device='cuda:0') ['the scored\\n Who most']\n",
      "tensor([13.0660, 12.5765, 12.5727, 12.1250, 11.6799], device='cuda:0') tensor([1080, 7881, 6526,   13, 4822], device='cuda:0') ['most highest Who\\n Most']\n",
      "tensor([13.0995, 11.3242, 11.1174, 10.7838,  9.8436], device='cuda:0') tensor([7661,   13, 6526, 6569, 3304], device='cuda:0') ['goals\\n Who football World']\n",
      "tensor([14.6844, 12.4059, 12.4013, 11.2102, 11.0514], device='cuda:0') tensor([  297, 28804,    13,  2270,   354], device='cuda:0') ['in?\\n ever for']\n",
      "tensor([13.2571, 12.6196, 12.1140, 11.0659, 10.7531], device='cuda:0') tensor([6569,  272, 1526,   13,  264], device='cuda:0') ['football the world\\n a']\n",
      "tensor([13.4613, 13.2408, 12.7001, 12.1766, 11.5643], device='cuda:0') tensor([  297, 28804,  1526,  3340,    13], device='cuda:0') ['in? world history\\n']\n",
      "tensor([13.5751, 11.6728, 11.6691, 11.2057, 10.2032], device='cuda:0') tensor([ 6569,  1080,   272,  1526, 28705], device='cuda:0') ['football most the world ']\n",
      "tensor([13.8669, 12.1898, 11.7734,  9.8231,  8.9810], device='cuda:0') tensor([  297,    13, 28804,     2, 28723], device='cuda:0') ['in\\n?</s>.']\n",
      "tensor([15.0083, 13.9435, 11.8900, 11.5381, 10.6310], device='cuda:0') tensor([6569, 7661, 1080,   13, 1526], device='cuda:0') ['football goals most\\n world']\n",
      "tensor([14.8934, 12.6709, 12.4023,  9.6979,  9.4176], device='cuda:0') tensor([  297,    13, 28804,     2,  6526], device='cuda:0') ['in\\n?</s> Who']\n",
      "tensor([15.3354, 13.6211, 11.8007, 11.0488, 10.2551], device='cuda:0') tensor([6569, 7661,   13, 1080, 1526], device='cuda:0') ['football goals\\n most world']\n",
      "tensor([15.0561, 12.2839, 11.4296,  9.8907,  9.0484], device='cuda:0') tensor([  297,    13, 28804,  6526,   659], device='cuda:0') ['in\\n? Who has']\n",
      "tensor([15.4819, 13.3487, 11.9811, 10.6168, 10.1695], device='cuda:0') tensor([6569, 7661,   13, 1080, 1526], device='cuda:0') ['football goals\\n most world']\n",
      "tensor([15.3535, 12.0312, 10.9452, 10.0520,  9.1416], device='cuda:0') tensor([  297,    13, 28804,  6526,   659], device='cuda:0') ['in\\n? Who has']\n",
      "tensor([15.6930, 13.2568, 12.0166, 10.5162, 10.2554], device='cuda:0') tensor([6569, 7661,   13, 1526, 1080], device='cuda:0') ['football goals\\n world most']\n",
      "tensor([15.5591, 12.0035, 10.7142, 10.2174,  9.0100], device='cuda:0') tensor([  297,    13, 28804,  6526, 28723], device='cuda:0') ['in\\n? Who.']\n",
      "tensor([15.9152, 13.2421, 11.9940, 10.7845,  9.9080], device='cuda:0') tensor([6569, 7661,   13, 1526, 1080], device='cuda:0') ['football goals\\n world most']\n",
      "tensor([15.6273, 11.9040, 10.4402,  9.9971,  9.0951], device='cuda:0') tensor([  297,    13, 28804,  6526, 28723], device='cuda:0') ['in\\n? Who.']\n",
      "tensor([16.1359, 13.0223, 11.9059, 10.7273,  9.8088], device='cuda:0') tensor([6569, 7661,   13, 1526, 1080], device='cuda:0') ['football goals\\n world most']\n",
      "tensor([15.8848, 11.8944, 10.4945,  9.6512,  9.2138], device='cuda:0') tensor([  297,    13, 28804,  6526, 28723], device='cuda:0') ['in\\n? Who.']\n",
      "tensor([16.4096, 12.8373, 11.9222, 10.6685,  9.8477], device='cuda:0') tensor([6569, 7661,   13, 1526, 1080], device='cuda:0') ['football goals\\n world most']\n",
      "tensor([16.1141, 12.0313, 10.4008,  9.6252,  9.2054], device='cuda:0') tensor([  297,    13, 28804,  6526, 28723], device='cuda:0') ['in\\n? Who.']\n",
      "tensor([16.6803, 12.6929, 12.0075, 10.8878,  9.9748], device='cuda:0') tensor([6569, 7661,   13, 1526, 1080], device='cuda:0') ['football goals\\n world most']\n",
      "tensor([16.2672, 12.0955, 10.3807,  9.7986,  9.1755], device='cuda:0') tensor([  297,    13, 28804,  6526, 28723], device='cuda:0') ['in\\n? Who.']\n",
      "tensor([16.8237, 12.4468, 11.9952, 11.2948, 10.1522], device='cuda:0') tensor([6569, 7661,   13, 1526, 1080], device='cuda:0') ['football goals\\n world most']\n",
      "tensor([16.3719, 12.0711, 10.5550, 10.0224,  9.1121], device='cuda:0') tensor([  297,    13, 28804,  6526, 28723], device='cuda:0') ['in\\n? Who.']\n",
      "tensor([16.9070, 12.5224, 12.1084, 11.4380,  9.9896], device='cuda:0') tensor([6569, 7661,   13, 1526, 1080], device='cuda:0') ['football goals\\n world most']\n",
      "tensor([16.4518, 12.0624, 10.4313, 10.1245,  9.0095], device='cuda:0') tensor([  297,    13, 28804,  6526, 28723], device='cuda:0') ['in\\n? Who.']\n",
      "tensor([16.9608, 12.7313, 12.3447, 11.4342, 10.0695], device='cuda:0') tensor([6569, 7661,   13, 1526, 1080], device='cuda:0') ['football goals\\n world most']\n",
      "tensor([16.4017, 12.0454, 10.2129,  9.9798,  9.1188], device='cuda:0') tensor([  297,    13,  6526, 28804,  7661], device='cuda:0') ['in\\n Who? goals']\n",
      "tensor([16.8825, 12.7898, 12.0759, 11.3655, 10.3563], device='cuda:0') tensor([6569, 7661,   13, 1526, 1080], device='cuda:0') ['football goals\\n world most']\n",
      "tensor([16.2669, 11.9442, 10.2805,  9.7904,  9.2110], device='cuda:0') tensor([  297,    13,  6526, 28804,  7661], device='cuda:0') ['in\\n Who? goals']\n",
      "tensor([16.7432, 12.7309, 11.7040, 11.2352, 10.4407], device='cuda:0') tensor([6569, 7661,   13, 1526, 6526], device='cuda:0') ['football goals\\n world Who']\n",
      "tensor([16.1239, 11.7948, 10.4390,  9.8166,  9.3166], device='cuda:0') tensor([  297,    13,  6526, 28804,  7661], device='cuda:0') ['in\\n Who? goals']\n",
      "tensor([16.7613, 12.8675, 11.5048, 11.0715, 10.5480], device='cuda:0') tensor([6569, 7661,   13, 1526, 6526], device='cuda:0') ['football goals\\n world Who']\n",
      "tensor([16.2000, 11.7633, 10.5578,  9.6750,  9.1286], device='cuda:0') tensor([  297,    13,  6526, 28804,  7661], device='cuda:0') ['in\\n Who? goals']\n",
      "tensor([16.9562, 13.0163, 11.5262, 11.0863, 10.3550], device='cuda:0') tensor([6569, 7661,   13, 1526, 6526], device='cuda:0') ['football goals\\n world Who']\n",
      "tensor([16.3570, 11.8565, 10.4827,  9.3466,  9.3234], device='cuda:0') tensor([  297,    13,  6526, 28804,  7661], device='cuda:0') ['in\\n Who? goals']\n",
      "tensor([17.0710, 13.0544, 11.5253, 11.3566, 10.3409], device='cuda:0') tensor([6569, 7661,   13, 1526, 6526], device='cuda:0') ['football goals\\n world Who']\n",
      "tensor([16.5019, 11.9489, 10.5065,  9.6111,  9.4838], device='cuda:0') tensor([  297,    13,  6526,  7661, 28804], device='cuda:0') ['in\\n Who goals?']\n",
      "tensor([17.1121, 12.9992, 11.8020, 11.5351, 10.4081], device='cuda:0') tensor([6569, 7661, 1526,   13, 6526], device='cuda:0') ['football goals world\\n Who']\n",
      "tensor([16.6175, 11.8600, 10.4477,  9.8960,  9.4838], device='cuda:0') tensor([  297,    13,  6526, 28804,  7661], device='cuda:0') ['in\\n Who? goals']\n",
      "tensor([17.2574, 12.9421, 12.4624, 11.4703, 10.1947], device='cuda:0') tensor([6569, 7661, 1526,   13, 6526], device='cuda:0') ['football goals world\\n Who']\n",
      "tensor([16.7288, 11.6467, 10.4136, 10.0329,  9.9992], device='cuda:0') tensor([  297,    13, 28804,     2,  6526], device='cuda:0') ['in\\n?</s> Who']\n",
      "tensor([17.0225, 12.7791, 12.1786, 11.4307, 10.1499], device='cuda:0') tensor([6569, 7661, 1526,   13, 6526], device='cuda:0') ['football goals world\\n Who']\n",
      "tensor([16.5956, 11.5863, 10.0231, 10.0110,  9.9828], device='cuda:0') tensor([  297,    13,     2,  6526, 28804], device='cuda:0') ['in\\n</s> Who?']\n",
      "tensor([16.8523, 12.7136, 12.0216, 11.3506, 10.1938], device='cuda:0') tensor([6569, 7661, 1526,   13, 6526], device='cuda:0') ['football goals world\\n Who']\n",
      "tensor([16.4950, 11.5943, 10.0379,  9.8811,  9.7040], device='cuda:0') tensor([ 297,   13, 6526,    2, 7661], device='cuda:0') ['in\\n Who</s> goals']\n",
      "tensor([16.6921, 12.4063, 11.8013, 11.3028, 10.0105], device='cuda:0') tensor([6569, 7661, 1526,   13, 1080], device='cuda:0') ['football goals world\\n most']\n",
      "tensor([16.4278, 11.5739,  9.8635,  9.8360,  9.3525], device='cuda:0') tensor([ 297,   13,    2, 6526, 7661], device='cuda:0') ['in\\n</s> Who goals']\n",
      "tensor([16.5071, 11.9455, 11.4943, 10.9790, 10.0640], device='cuda:0') tensor([6569, 7661, 1526,   13, 1080], device='cuda:0') ['football goals world\\n most']\n"
     ]
    }
   ],
   "source": [
    "for t in outputs.scores:\n",
    "    values, indices = torch.sort(t)\n",
    "    scores = values[0,-5:].flip(dims=[0])\n",
    "    tokens = indices[0,-5:].flip(dims=[0])\n",
    "    print(scores, tokens, [tokenizer.decode(tokens)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ab9e3d3f-2dc0-4f89-9553-3442d6c0d8e4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Explain the significance and applications of the formula a²+b²=c² in number theory.\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = tokenizer.batch_decode(output_ids.sequences, skip_special_tokens=True, clean_up_tokenization_spaces=False)\n",
    "output[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "191fe61b-04b8-4228-a323-8099be747706",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 64])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_ids.sequences.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d0ca24ba-c196-452b-b41d-c0ca24795443",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "argument 'ids': 'str' object cannot be interpreted as an integer",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[28], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtokenizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutput_ids\u001b[49m\u001b[43m,\u001b[49m\u001b[43mskip_special_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:3825\u001b[0m, in \u001b[0;36mPreTrainedTokenizerBase.decode\u001b[0;34m(self, token_ids, skip_special_tokens, clean_up_tokenization_spaces, **kwargs)\u001b[0m\n\u001b[1;32m   3822\u001b[0m \u001b[38;5;66;03m# Convert inputs to python lists\u001b[39;00m\n\u001b[1;32m   3823\u001b[0m token_ids \u001b[38;5;241m=\u001b[39m to_py_obj(token_ids)\n\u001b[0;32m-> 3825\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_decode\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   3826\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtoken_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3827\u001b[0m \u001b[43m    \u001b[49m\u001b[43mskip_special_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mskip_special_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3828\u001b[0m \u001b[43m    \u001b[49m\u001b[43mclean_up_tokenization_spaces\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclean_up_tokenization_spaces\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3829\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3830\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/transformers/tokenization_utils_fast.py:625\u001b[0m, in \u001b[0;36mPreTrainedTokenizerFast._decode\u001b[0;34m(self, token_ids, skip_special_tokens, clean_up_tokenization_spaces, **kwargs)\u001b[0m\n\u001b[1;32m    623\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(token_ids, \u001b[38;5;28mint\u001b[39m):\n\u001b[1;32m    624\u001b[0m     token_ids \u001b[38;5;241m=\u001b[39m [token_ids]\n\u001b[0;32m--> 625\u001b[0m text \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_tokenizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtoken_ids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mskip_special_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mskip_special_tokens\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    627\u001b[0m clean_up_tokenization_spaces \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    628\u001b[0m     clean_up_tokenization_spaces\n\u001b[1;32m    629\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m clean_up_tokenization_spaces \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    630\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclean_up_tokenization_spaces\n\u001b[1;32m    631\u001b[0m )\n\u001b[1;32m    632\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m clean_up_tokenization_spaces:\n",
      "\u001b[0;31mTypeError\u001b[0m: argument 'ids': 'str' object cannot be interpreted as an integer"
     ]
    }
   ],
   "source": [
    "tokenizer.decode(output_ids,skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "29ee3533-aced-43cf-94e4-d0a4cd7b344b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The The\n",
      "ain What difference of importance of the following for2 +b²=c². the theory.\n",
      "abr>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def logits_to_generate(logits, max_length=None):\n",
    "    \"\"\"\n",
    "    Convert logits to model.generate-like output tensor using greedy decoding.\n",
    "    \n",
    "    Args:\n",
    "        logits (torch.Tensor): Logits tensor of shape (batch_size, sequence_length, vocab_size).\n",
    "        max_length (int): Maximum length of the generated sequence. Default is None.\n",
    "    \n",
    "    Returns:\n",
    "        torch.Tensor: Generated tensor of shape (batch_size, sequence_length).\n",
    "    \"\"\"\n",
    "    batch_size, sequence_length, vocab_size = logits.shape\n",
    "    \n",
    "    # Select the word with the highest logit value at each timestep\n",
    "    generated = torch.argmax(logits, dim=-1)\n",
    "    \n",
    "    # Truncate to max_length\n",
    "    if max_length is not None:\n",
    "        generated = generated[:, :max_length]\n",
    "    \n",
    "    return generated\n",
    "\n",
    "# 示例用法\n",
    "logits = model(**inputs).logits\n",
    "generated = logits_to_generate(logits)\n",
    "print(tokenizer.decode(generated[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "47f1e768-d93e-4783-bbde-8d6e2d6539f5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "out_logits = model(**inputs).logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "91e36f3f-3a45-436d-ae48-714a062ea019",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 28, 32000])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_logits.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1a30b27f-b34f-4c4f-8f04-5cb6864783e0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "def truncate(text: str, delimiters: List[str]) -> str:\n",
    "    for d in delimiters:\n",
    "        text = text.split(d)[0]\n",
    "    return text\n",
    "\n",
    "def generate(prompt: str, max_new_tokens:int,*args, **kwargs) -> str:\n",
    "    '''Generate a single response'''\n",
    "    input_ids = tokenizer.encode(prompt, return_tensors=\"pt\").to(device)\n",
    "    output_ids = model.generate(input_ids, max_new_tokens = max_new_tokens, do_sample=True, **kwargs)\n",
    "    input_length = input_ids.shape[1]\n",
    "    decoded = tokenizer.batch_decode(output_ids[:, input_length:], skip_special_tokens=True)[0]\n",
    "    return decoded\n",
    "\n",
    "def generate_responses(prompts: List[str], \n",
    "                       max_new_tokens:int = 256, \n",
    "                       delimiters: List[str] = ['\\n\\n', tokenizer.eos_token], \n",
    "                       *args,\n",
    "                       **kwargs) -> List[str]:\n",
    "    '''\n",
    "    Generate responses for a list of prompts. We don't use batch encode here.\n",
    "\n",
    "    Args:\n",
    "        prompts (List[str]): A list of prompts.\n",
    "        max_new_tokens (int, optional): The maximum number of tokens to generate for each response. Defaults to 256.\n",
    "        delimiters (List[str], optional): A list of delimiters used to truncate the generated response. Defaults to ['\\n\\n', tokenizer.eos_token].\n",
    "        *args: Variable length argument list.\n",
    "        **kwargs: Arbitrary keyword arguments.\n",
    "\n",
    "    Returns:\n",
    "        List[str]: A list of generated responses.\n",
    "    '''\n",
    "    responses = []\n",
    "    for p in tqdm(prompts):\n",
    "        r = generate(p, max_new_tokens, *args, **kwargs)\n",
    "        responses.append(truncate(r, delimiters))\n",
    "    return responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3af0b978-c1e2-4a44-ad19-a0b7dd225d49",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "100%|██████████| 1/1 [00:05<00:00,  5.35s/it]\n"
     ]
    }
   ],
   "source": [
    "responses = generate_responses(prompts[:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b76df359-a75b-489d-9d3a-8cb1c6b75405",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[    1, 12628,   396,  ..., 16981, 28747, 28705]], device='cuda:0')"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs = tokenizer(prompts[0], return_tensors=\"pt\").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "fb5b7ce8-b055-4a41-9b44-931090b6b242",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    }
   ],
   "source": [
    "oids = model.generate(**inputs, max_new_tokens=256, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "be94d455-73b5-4695-8ace-345df7232811",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1765"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs.input_ids.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "7990d594-4f34-4c1c-ba28-23695405fac6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[    1, 12628,   396,  ...,    13,    13,    13]], device='cuda:0')"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "7092e648-5bc6-48f8-9282-521299ab33d5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Given an ambiguous question, figure out its interpretations and answer them one by one. \\nQuestion: Who played bonnie in gone with the wind? \\nAnswer: This question is ambiguous in terms of which version or adaptation of Gone with the Wind is being referred to. In order to figure out its interpretations, we need to consider different versions or adaptations of Gone with the Wind. Gone with the Wind has two versions or adaptations: the 1939 film Gone with the Wind or the 2008 musical Gone with the Wind. Therefore, this question has 2 interpretations: (1) Who played Bonnie in the 1939 film Gone with the Wind? (2) Who played Bonnie in the 2008 musical Gone with the Wind? The answers to all interpretations are: (1) The 1939 film Gone with the Wind’s character Bonnie was played by Eleanore Cammack \"Cammie\" King. (2) The 2008 musical Gone with the Wind’s character Bonnie was played by Leilah de Meza. \\n\\nGiven an ambiguous question, figure out its interpretations and answer them one by one. \\nQuestion: What is the second largest city in the usa? \\nAnswer: This question is ambiguous in terms of the criteria being used to determine the second largest city in the USA. In order to figure out its interpretations, we need to consider different criteria to determine a city’s size. City size can be measured by two criteria: population or area. Therefore, this question has 2 interpretations: (1) What is the second largest city in the USA by population? (2) What is the second largest city in the USA by area? The answers to all interpretations are: (1) The second largest city in the USA by population is Los Angeles, California. (2) The second largest city in the USA by area is Juneau, Alaska. \\n\\nGiven an ambiguous question, figure out its interpretations and answer them one by one. \\nQuestion: When was bohemian rhapsody released as a single? \\nAnswer: This question is ambiguous in terms of which country’s release of the single is being referred to. In order to figure out its interpretations, we need to consider different countries where Bohemian Rhapsody is released. Bohemian Rhapsody was released in the United Kingdom and in the United States on different dates. Therefore, this question has 2 interpretations: (1) When was Bohemian Rhapsody released as a single in the United Kingdom? (2) When was Bohemian Rhapsody released as a single in the United States? The answers to all interpretations are: (1) Bohemian Rhapsody was released as a single in the United Kingdom on 31 October 1975. (2) Bohemian Rhapsody was released as a single in the United States on December 1975. \\n\\nGiven an ambiguous question, figure out its interpretations and answer them one by one. \\nQuestion: Where do the philadelphia eagles play their home games? \\nAnswer: This question is ambiguous in terms of which specific location or venue is being referred to. In order to figure out its interpretations, we need to consider the different possible locations or venues that could be considered the home field of the Philadelphia Eagles. These include the city, the sports complex, or the stadium. Therefore, this question has 3 interpretations: (1) What city do the Philadelphia Eagles play their home games? (2) In what sports complex do the Philadelphia Eagles play their home games? (3) What stadium do the Philadelphia Eagles play their home games? The answers to all interpretations are: (1) Philadelphia Eagles play their home games in the city Philadelphia. (2) Philadelphia Eagles play their home games in the South Philadelphia Sports Complex. (3) Philadelphia Eagles play their home games in the Lincoln Financial Field stadium. \\n\\nGiven an ambiguous question, figure out its interpretations and answer them one by one. \\nQuestion: When did xbox one come out in australia? \\nAnswer: This question is ambiguous in terms of which specific version of the Xbox One is being referred to. In order to figure out its interpretations, we need to consider the different versions of the Xbox One that have been released. Xbox One has two versions: the Xbox One video game console or the Xbox One X high-end model. Therefore, this question has 2 interpretations: (1) When did the Xbox One release in Australia? (2) When did the Xbox One X release in Australia? The answers to all interpretations are: (1) The Xbox One video game console was released in Australia on November 22, 2013. (2) The Xbox One X video game console was released in Australia on November 7, 2017. \\n\\nGiven an ambiguous question, figure out its interpretations and answer them one by one. \\nQuestion: When does the movie summer of 84 come out? \\nAnswer: This question is ambiguous in terms of which release of the movie is being referred to. In order to figure out its interpretations, we need to consider different releases of the movie Summer of ’84. The movie Summer of ’84 is first released at the Sundance Festival before it’s released throughout the US. Therefore, this question has 2 interpretations: (1) When did the movie Summer of ’84 first release at the Sundance Festival? (2) When did the movie Summer of ’84 first release throughout the US? The answers to all interpretations are: (1) Summer of ’84 was released at the Sundance Festival on January 22, 2018. (2) Summer of ’84 was released throughout the US on August 10, 2018.\\n\\nGiven an ambiguous question, figure out its interpretations and answer them one by one.\\nQuestion: What was roy orbison’s first number one hit?\\nAnswer: This question is ambiguous in terms of which specific chart or region is being referred to. In order to figure out its interpretations, we need to consider the different charts and regions where Roy Orbison’s music was popular. Roy Orbison is popular in both the US Hot 100 and Canada, and the UK and Ireland. Therefore, this question has 2 interpretations: (1) What was Roy Orbison’s first number one hit in the US Hot 100 and Canada? (2) What was Roy Orbison’s first number one hit in the UK and Ireland? The answers to all interpretations are: (1) Running Scared was the first number one hit for Roy Orbison in the US Hot 100 and Canada. (2) Only the Lonely (Know the Way I Feel) was the first number one hit for Roy Orbison in the UK and Ireland.\\n\\nGiven an ambiguous question, figure out its interpretations and answer them one by one.\\nQuestion: What is the criminal’s name in the breakfast club?\\nAnswer: This question is ambiguous in terms of which specific name is being referred to - the character’s name or the actor’s name. In order to figure out its interpretations, we need to consider both possibilities: the character’s name or the actor’s name. Therefore, this question has 2 interpretations: (1) What is the criminal’s character name in The Breakfast Club? (2) What is the the name of the actor who played the criminal in The Breakfast Club? The answers to all interpretations are: (1) John Bender was the name of the criminal’s character in The Breakfast Club. (2) Judd Nelson was the actor of the criminal in The Breakfast Club.\\n\\nGiven an ambiguous question, figure out its interpretations and answer them one by one.\\nQuestion: Who has the highest goals in world football?\\nAnswer: \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n'"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(oids[0],skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2988381-2c86-42bc-989e-73a72bb2ff6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_key_information(pred: str) -> str:\n",
    "    '''Extract key information from the response.'''\n",
    "    prefix_to_remove=['this question has 2 interpretations: (.*)$',\n",
    "                      'this question has 1 interpretation: (.*)$']\n",
    "    for pattern in prefix_to_remove:\n",
    "        pred = pred.strip().split('\\n\\n', 1)[0].strip()\n",
    "        find = re.compile(pattern).search(pred)\n",
    "        if find:\n",
    "            pred = find.group(1)\n",
    "            break\n",
    "    if find is None:\n",
    "        logging.warning(f\"Cannot extract key information from the response: {pred}\")\n",
    "    pred = re.sub(r'\\(\\d+\\)\\s', '', pred) # remove the index numbers\n",
    "    return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0c69d5b-e1af-483b-9049-a355cf657807",
   "metadata": {},
   "outputs": [],
   "source": [
    "answers = [extract_key_information(r) for r in responses]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9778a1d9-a54d-4e83-93d2-7c725a113b32",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.add_column('responses', responses)\n",
    "dataset = dataset.add_column('responses', responses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c313040d-ceed-478a-ab8f-c2fc3cdcc23e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.to_json('llama2-7b-chat')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
